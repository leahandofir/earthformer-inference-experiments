{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLM3f1qxHbQl7Gxsw9vO5w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leahandofir/earthformer-inference-experiments/blob/main/google_colab_experiments/fss_debug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "UwmjFpHnzpo_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class FSSLoss(torch.nn.Module):\n",
        "    # TODO: write what every input is suppose to be\n",
        "    def __init__(self,\n",
        "                 threshold: int, # TODO: maybe we can try discretization of more then 1 value?\n",
        "                 scale: int,\n",
        "                 hwc: tuple,\n",
        "                 seq_len: int,\n",
        "                 minimize: bool = True,\n",
        "                 smooth_factor: int = 20,\n",
        "                 pixel_scale: bool = True,\n",
        "                 strategy: str = \"tanh\",\n",
        "                 device: torch.device = torch.device('cuda')):\n",
        "        super(FSSLoss, self).__init__()\n",
        "        self.threshold = threshold\n",
        "        self.scale = scale\n",
        "        self.hwc = hwc\n",
        "        self.seq_len = seq_len\n",
        "        self.minimize = minimize\n",
        "        self.smooth_factor = smooth_factor\n",
        "        self.pixel_scale = 255 if pixel_scale else 1\n",
        "        self.strategy = strategy\n",
        "        self.neighborhood_filter_dim = (self.seq_len * self.hwc[-1], self.seq_len * self.hwc[-1], self.scale, self.scale)\n",
        "        self.neighborhood_filter_mat = torch.full(self.neighborhood_filter_dim, 1 / self.scale ** 2, device=device)\n",
        "        # print(self.neighborhood_filter_mat)\n",
        "        # print(self.neighborhood_filter_mat.shape)\n",
        "\n",
        "    # warning - heavily assumes layout NTWHC!\n",
        "\n",
        "    def _preprocess(self, batch):\n",
        "        # the input is of shape NTHWC\n",
        "        # rescale pixels back to 0-255\n",
        "        batch = batch * self.pixel_scale\n",
        "        # print(batch.shape)\n",
        "\n",
        "        # flatten sequence to 3-dim by increasing number of channels, the resulted shape is NCWH\n",
        "        # (used negative indices in order to handle both batch-input and single-input)\n",
        "        batch = torch.flatten(batch.moveaxis(-1, -3), start_dim=-4, end_dim=-3)\n",
        "\n",
        "        # 'binarize' data\n",
        "        if self.strategy == \"hardtanh\":\n",
        "            # hardtanh is applied element wise. for every coordinate x:\n",
        "            #   if x > max_val -> max_val\n",
        "            #   if x < min_val -> min_val\n",
        "            #   else x\n",
        "            # batch - self.threshold gives us <0 for every pixel <threshold and >=0 for every pixel >=threshold.\n",
        "            # applying the smooth factor makes the values between 0 and 1 to potentially become bigger than 1 so the discretization is \"sharper\".\n",
        "            batch = F.hardtanh(self.smooth_factor * (batch - self.threshold), min_val=0, max_val=1)\n",
        "\n",
        "        if self.strategy == \"tanh\":\n",
        "            batch = 0.5 * torch.tanh(self.smooth_factor * (batch - self.threshold)) + 0.5\n",
        "        # print(\"after tanh:\")\n",
        "        # print(batch.shape)\n",
        "        # print(batch[0,:,:,0])\n",
        "        return batch\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        # preprocess\n",
        "        # print(\"output\")\n",
        "        output = self._preprocess(output)\n",
        "        # print(\"input\")\n",
        "        target = self._preprocess(target)\n",
        "\n",
        "        # compute each neighborhood's average value by applying convolution filter and convert shape back to NHWC\n",
        "        if self.scale > 1:\n",
        "            F_n = F.conv2d(output, self.neighborhood_filter_mat).moveaxis(-3, -1)\n",
        "            # print(\"Fn\")\n",
        "            # print(F_n[0,:,:,0])\n",
        "            # print(F_n.shape)\n",
        "            O_n = F.conv2d(target, self.neighborhood_filter_mat).moveaxis(-3, -1)\n",
        "        else:\n",
        "            F_n = output\n",
        "            O_n = target\n",
        "\n",
        "        numerator = ((F_n - O_n) ** 2).sum(dim=-2).sum(dim=-2) # TODO: why we sum twice?\n",
        "        denominator = (F_n ** 2).sum(dim=-2).sum(dim=-2) + (O_n ** 2).sum(dim=-2).sum(dim=-2)\n",
        "        print(f\"up: {numerator[0,0]}\\tdown: {denominator[0,0]}\\tdown F_N: {(F_n ** 2).sum(dim=-2).sum(dim=-2)[0,0]}\\tdown O_n: {(O_n ** 2).sum(dim=-2).sum(dim=-2)[0,0]}\")\n",
        "\n",
        "        # compute the mean loss for each sequence (loss is computed frame by frame)\n",
        "        fss_per_batch = (1 - numerator / denominator).mean(dim=-1)\n",
        "\n",
        "        # return the average loss over all batches, multiply by -1 if we want to minimize\n",
        "        fss_avg = fss_per_batch.mean()\n",
        "        return 1.0 - fss_avg if self.minimize else fss_avg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download cloudformer repo & cd into its main folder\n",
        "%cd /content\n",
        "!rm -rf /content/cloud-forecasting-transformer\n",
        "!git clone https://github.com/leahandofir/cloud-forecasting-transformer.git\n",
        "%cd cloud-forecasting-transformer"
      ],
      "metadata": {
        "id": "w9aXtQ-BSRvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oizHOYofSUAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing PyPNG\n",
        "# !python -m pip install git+https://gitlab.com/drj11/pypng@pypng-0.20220715.0\n",
        "!pip install pypng"
      ],
      "metadata": {
        "id": "_APKT7JEST2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import png\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def get_img(path):\n",
        "  pixels = png.Reader(file=open(path, \"rb\")).asRGBA8()[2]\n",
        "  np_arr = np.array([list(row) for row in pixels]).reshape(600,600,4)\n",
        "  grayscale = 0.299 * np_arr[:,:,0] + 0.587 * np_arr[:,:,1] + 0.114 * np_arr[:,:,2]\n",
        "  scaled_pixels = grayscale / 255.0\n",
        "  return scaled_pixels"
      ],
      "metadata": {
        "id": "XotszhnUU_1O"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_img = get_img('/content/drive/MyDrive/data_from_IMS/ims_ir_png_samples/202301010000.png')\n",
        "\n",
        "seq_from_real = np.stack([real_img for i in range(12)])\n",
        "\n",
        "batch_from_real = np.expand_dims(seq_from_real, 0)\n",
        "batch_from_real = np.expand_dims(batch_from_real, -1)\n",
        "\n",
        "batch_from_real = torch.Tensor(batch_from_real)"
      ],
      "metadata": {
        "id": "uRq9R3NbUKoo"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_img_2 = get_img('/content/drive/MyDrive/data_from_IMS/ims_ir_png_samples/202301010300.png')\n",
        "\n",
        "seq_from_real_2 = np.stack([real_img_2 for i in range(12)])\n",
        "\n",
        "batch_from_real_2 = np.expand_dims(seq_from_real_2, 0)\n",
        "batch_from_real_2 = np.expand_dims(batch_from_real_2, -1)\n",
        "\n",
        "batch_from_real_2 = torch.Tensor(batch_from_real_2)"
      ],
      "metadata": {
        "id": "ctZ_Owgka-9v"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_data = torch.rand((1,12,600,600,1)) #NTWHC\n",
        "random_data_negative = -torch.rand((1,12,600,600,1)) #NTWHC\n",
        "random_data_mixed = torch.rand((1,12,600,600,1)) - 0.4 #NTWHC\n",
        "\n",
        "random_data_barely_negative = torch.rand((1,12,600,600,1)) #NTWHC\n",
        "m = torch.min(random_data_barely_negative)\n",
        "random_data_barely_negative = random_data_barely_negative - m - 10 ** (-2)\n",
        "print(m)\n",
        "\n",
        "random_data_large = torch.rand((1,12,600,600,1)) + 0.5 #NTWHC"
      ],
      "metadata": {
        "id": "7ocYhzmeVGve"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = FSSLoss(threshold=160, scale=10, hwc=(600,600,1), seq_len=12, minimize=True, device='cpu')"
      ],
      "metadata": {
        "id": "YzOrNgBWVNkD"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"positive random: {loss(random_data, batch_from_real)}\\n\")\n",
        "print(f\"negative random: {loss(random_data_negative, batch_from_real)}\\n\")\n",
        "print(f\"mixed    random: {loss(random_data_mixed, batch_from_real)}\\n\")\n",
        "print(f\"barely negative random: {loss(random_data_barely_negative, batch_from_real)}\\n\")\n",
        "print(f\"positive large random: {loss(random_data_large, batch_from_real)}\\n\")\n",
        "print(f\"real vs real: {loss(batch_from_real_2, batch_from_real)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo4w4U1cVmAC",
        "outputId": "3f87e026-b5a2-458e-e1b3-9c31b144d79c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "up: 7065064.0\tdown: 17423824.0\tdown F_N: 7001151.0\tdown O_n: 10422673.0\n",
            "positive random: 0.40548306703567505\n",
            "\n",
            "up: 10422673.0\tdown: 10422673.0\tdown F_N: 0.0\tdown O_n: 10422673.0\n",
            "negative random: 1.0\n",
            "\n",
            "up: 10422673.0\tdown: 10422673.0\tdown F_N: 0.0\tdown O_n: 10422673.0\n",
            "mixed    random: 1.0\n",
            "\n",
            "up: 6959588.0\tdown: 17044396.0\tdown F_N: 6621724.0\tdown O_n: 10422673.0\n",
            "barely negative random: 0.40832120180130005\n",
            "\n",
            "up: 24457000.0\tdown: 48734048.0\tdown F_N: 38311376.0\tdown O_n: 10422673.0\n",
            "positive large random: 0.5018463134765625\n",
            "\n",
            "up: 3782355.5\tdown: 23073388.0\tdown F_N: 12650715.0\tdown O_n: 10422673.0\n",
            "real vs real: 0.1639271378517151\n",
            "\n"
          ]
        }
      ]
    }
  ]
}