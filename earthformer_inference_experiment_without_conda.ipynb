{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMygGVyG+WHKYv+zVv1COLM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leahandofir/earthformer-inference-experiments/blob/main/earthformer_inference_experiment_without_conda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genral:\n",
        "**The goal** - try to understand what we need to do to run model(x) and get a result. **STILL DID NOT REACHED THAT GOAL**\n",
        "\n",
        "**The structure of the code** - \n",
        "- Train\n",
        "- Test\n",
        "- The architecture of the model - the model recieves an example x and returns prediction y. The model has a function named \"eval\" to turn off behaviors that are relevent in the training process (like dropout and batch normalization), this is realy important to do when inferancing!\n",
        "- Data set - the code that responsible for assamble the raw samples as python data structures. This is a class that usually inhirites from a DataSet class of pytorch. Has __getItem__ method that recieves an index and returns a sample x with that index. Also has a __len__ methos that returns the number of samples in the data set.\n",
        "- Data Loader - wraps the Data set. Has a certain number of workers to concurrantly and efficiently read the data set. Has a queue that always prepare the next mini batch so the usage of the GPU will be efficient. \n",
        "collate_fn - a function that aggragates a batch of samples from the data set loader in a data structure that the model can train on.\n",
        "comment - we want the batch to be as large as possible to has less transitions from the CPU to the GPU.\n",
        "\n",
        "Solving error 21/4/2023:\n",
        "\n",
        "Tried to solve the error `ImportError: cannot import name '_PATH' from 'pytorch_lightning.utilities.types`\n",
        "with some google advices with no success.\n",
        "after that saw this error in the pip outputs:\n",
        "```\n",
        "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
        "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.12.1+cu116 which is incompatible.\n",
        "```\n",
        "also this:\n",
        "```\n",
        "ERROR: pip's dependency resolver does not currently \n",
        "take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
        "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.12.1+cu116 which is incompatible.\n",
        "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.12.1+cu116 which is incompatible.\n",
        "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.12.1+cu116 which is incompatible.\n",
        "```\n",
        "so decided to try and install everything with cuda 11.8 and let pip decide the versions.\n",
        "after that it just worked.\n",
        "general good things to copy from their code:\n",
        "- they use os.path a lot. checking if directories exist, and if not they create them. we need our code to be as little as possible dependent on the machine.\n",
        "- they have utils directory of all the general needed things (like download a given url)\n",
        "\n"
      ],
      "metadata": {
        "id": "NiVbVDm2BsIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependencies"
      ],
      "metadata": {
        "id": "p-MVktqwqevf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# install dependencies\n",
        "pip install --upgrade pip\n",
        "python3 -m pip install torch==2.0.0+cu118 torchvision -f https://download.pytorch.org/whl/torch_stable.html\n",
        "python3 -m pip install \"pytorch_lightning>=1.6.4,<1.8.0\"\n",
        "python3 -m pip install xarray netcdf4 opencv-python\n",
        "git clone https://github.com/amazon-science/earth-forecasting-transformer.git\n",
        "cd earth-forecasting-transformer\n",
        "python3 -m pip install -U -e . --no-build-isolation\n",
        "pip install -v --disable-pip-version-check --no-cache-dir pytorch-extension git+https://github.com/NVIDIA/apex.git"
      ],
      "metadata": {
        "id": "Y_BenJuxzolw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# install aws cli to check out sevir dataset\n",
        "curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
        "unzip awscliv2.zip\n",
        "sudo ./aws/install"
      ],
      "metadata": {
        "id": "kNYJH6W7qIqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# maybe it's better then the above! try only this next time\n",
        "!apt-get install awscli"
      ],
      "metadata": {
        "id": "DvU7i1Plutxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# checking the aws cli installation and the size of the sevir dataset\n",
        "aws --version"
      ],
      "metadata": {
        "id": "wXptKGncqPpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/earth-forecasting-transformer/src"
      ],
      "metadata": {
        "id": "ySPGQ513z09o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is from tests/unittests/test_pretrained_checkpoints.py:"
      ],
      "metadata": {
        "id": "PADYz1yTpy6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import os\n",
        "from omegaconf import OmegaConf\n",
        "import pytest\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import torchmetrics\n",
        "from einops import rearrange\n",
        "from earthformer.config import cfg\n",
        "from earthformer.utils.checkpoint import s3_download_pretrained_ckpt\n",
        "from earthformer.utils.layout import layout_to_in_out_slice\n",
        "from earthformer.utils.utils import download\n",
        "from earthformer.cuboid_transformer.cuboid_transformer import CuboidTransformerModel\n",
        "from earthformer.cuboid_transformer.cuboid_transformer_unet_dec import CuboidTransformerAuxModel\n",
        "\n",
        "\n",
        "NUM_TEST_ITER = 16  # max = 32 since saved `unittest_data.pt` only contains the first 0 to 31 data entries.\n",
        "test_data_dir = os.path.join(cfg.root_dir, \"tests\", \"unittests\", \"test_pretrained_checkpoints_data\")\n",
        "\n",
        "def s3_download_unittest_data(data_name):\n",
        "    test_data_path = os.path.join(test_data_dir, data_name)\n",
        "    if not os.path.exists(test_data_path):\n",
        "        os.makedirs(test_data_dir, exist_ok=True)\n",
        "        download(url=f\"s3://deep-earth/experiments/earthformer/unittests/{data_name}\", path=test_data_path)\n",
        "\n",
        "\n",
        "def config_cuboid_transformer(cfg, model_type=\"CuboidTransformerModel\"):\n",
        "    model_cfg = OmegaConf.to_object(cfg.model)\n",
        "    num_blocks = len(model_cfg[\"enc_depth\"])\n",
        "    if isinstance(model_cfg[\"self_pattern\"], str):\n",
        "        enc_attn_patterns = [model_cfg.pop(\"self_pattern\")] * num_blocks\n",
        "    else:\n",
        "        enc_attn_patterns = OmegaConf.to_container(model_cfg.pop(\"self_pattern\"))\n",
        "    model_cfg[\"enc_attn_patterns\"] = enc_attn_patterns\n",
        "    if isinstance(model_cfg[\"cross_self_pattern\"], str):\n",
        "        dec_self_attn_patterns = [model_cfg.pop(\"cross_self_pattern\")] * num_blocks\n",
        "    else:\n",
        "        dec_self_attn_patterns = OmegaConf.to_container(model_cfg.pop(\"cross_self_pattern\"))\n",
        "    model_cfg[\"dec_self_attn_patterns\"] = dec_self_attn_patterns\n",
        "    if isinstance(model_cfg[\"cross_pattern\"], str):\n",
        "        dec_cross_attn_patterns = [model_cfg.pop(\"cross_pattern\")] * num_blocks\n",
        "    else:\n",
        "        dec_cross_attn_patterns = OmegaConf.to_container(model_cfg.pop(\"cross_pattern\"))\n",
        "    model_cfg[\"dec_cross_attn_patterns\"] = dec_cross_attn_patterns\n",
        "    if model_type == \"CuboidTransformerModel\":\n",
        "        model = CuboidTransformerModel(**model_cfg)\n",
        "    elif model_type == \"CuboidTransformerAuxModel\":\n",
        "        model = CuboidTransformerAuxModel(**model_cfg)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid model_type {model_type}. Must be 'CuboidTransformerModel' or ''.\")\n",
        "    return model\n",
        "\n",
        "def test_sevir():\n",
        "    pretrained_ckpt_name = \"earthformer_sevir.pt\"\n",
        "    test_data_name = \"unittest_sevir_data_bs1_idx0to31.pt\"\n",
        "    s3_download_unittest_data(data_name=test_data_name)\n",
        "    test_data_path = os.path.join(test_data_dir, test_data_name)\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    # Load pretrained model\n",
        "    pretrained_cfg_path = os.path.join(cfg.root_dir, \"scripts\", \"cuboid_transformer\", \"sevir\", \"earthformer_sevir_v1.yaml\")\n",
        "    pretrained_cfg = OmegaConf.load(open(pretrained_cfg_path, \"r\"))\n",
        "    model = config_cuboid_transformer(\n",
        "        cfg=pretrained_cfg,\n",
        "        model_type=\"CuboidTransformerModel\").to(device)\n",
        "    model.eval()\n",
        "    if not os.path.exists(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name)):\n",
        "        s3_download_pretrained_ckpt(ckpt_name=pretrained_ckpt_name,\n",
        "                                    save_dir=cfg.pretrained_checkpoints_dir,\n",
        "                                    exist_ok=False)\n",
        "    state_dict = torch.load(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name),\n",
        "                            map_location=device)\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(state_dict=state_dict, strict=False)\n",
        "    assert len(missing_keys) == 0, f\"missing_keys {missing_keys} when loading pretrained state_dict.\"\n",
        "    assert len(unexpected_keys) == 0, f\"missing_keys {unexpected_keys} when loading pretrained state_dict.\"\n",
        "    # Test on SEVIR test\n",
        "    layout_cfg = pretrained_cfg.layout\n",
        "    in_slice, out_slice = layout_to_in_out_slice(layout=layout_cfg.layout,\n",
        "                                                 in_len=layout_cfg.in_len,\n",
        "                                                 out_len=layout_cfg.out_len)\n",
        "    test_mse_metrics = torchmetrics.MeanSquaredError().to(device)\n",
        "    test_mae_metrics = torchmetrics.MeanAbsoluteError().to(device)\n",
        "    test_data = torch.load(test_data_path)\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_data:\n",
        "            data_seq = batch['vil'].contiguous().to(device)\n",
        "            x = data_seq[in_slice]\n",
        "            y = data_seq[out_slice]\n",
        "            y_hat = model(x)\n",
        "            test_mse_metrics(y_hat, y)\n",
        "            test_mae_metrics(y_hat, y)\n",
        "            counter += 1\n",
        "            if counter >= NUM_TEST_ITER:\n",
        "                break\n",
        "    test_mse = test_mse_metrics.compute()\n",
        "    test_mae = test_mae_metrics.compute()\n",
        "    assert test_mse < 1E-2\n",
        "    assert test_mae < 5E-2\n",
        "\n",
        "def test_enso():\n",
        "    pretrained_ckpt_name = \"earthformer_icarenso2021.pt\"\n",
        "    test_data_name = \"unittest_icarenso2021_data_bs1_idx0to31.pt\"\n",
        "    s3_download_unittest_data(data_name=test_data_name)\n",
        "    test_data_path = os.path.join(test_data_dir, test_data_name)\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    # Load pretrained model\n",
        "    pretrained_cfg_path = os.path.join(cfg.root_dir, \"scripts\", \"cuboid_transformer\", \"enso\", \"earthformer_enso_v1.yaml\")\n",
        "    pretrained_cfg = OmegaConf.load(open(pretrained_cfg_path, \"r\"))\n",
        "    model = config_cuboid_transformer(\n",
        "        cfg=pretrained_cfg,\n",
        "        model_type=\"CuboidTransformerModel\").to(device)\n",
        "    model.eval()\n",
        "\n",
        "    if not os.path.exists(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name)):\n",
        "        s3_download_pretrained_ckpt(ckpt_name=pretrained_ckpt_name,\n",
        "                                    save_dir=cfg.pretrained_checkpoints_dir,\n",
        "                                    exist_ok=False)\n",
        "    state_dict = torch.load(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name),\n",
        "                            map_location=device)\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(state_dict=state_dict, strict=False)\n",
        "    assert len(missing_keys) == 0, f\"missing_keys {missing_keys} when loading pretrained state_dict.\"\n",
        "    assert len(unexpected_keys) == 0, f\"missing_keys {unexpected_keys} when loading pretrained state_dict.\"\n",
        "    # Test on ENSO test\n",
        "    layout_cfg = pretrained_cfg.layout\n",
        "    in_slice, out_slice = layout_to_in_out_slice(layout=layout_cfg.layout,\n",
        "                                                 in_len=layout_cfg.in_len,\n",
        "                                                 out_len=layout_cfg.out_len)\n",
        "    test_mse_metrics = torchmetrics.MeanSquaredError().to(device)\n",
        "    test_mae_metrics = torchmetrics.MeanAbsoluteError().to(device)\n",
        "    test_data = torch.load(test_data_path)\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_data:\n",
        "            sst_seq, nino_target = batch\n",
        "            data_seq = sst_seq.float().unsqueeze(-1).to(device)\n",
        "            x = data_seq[in_slice]\n",
        "            y = data_seq[out_slice]\n",
        "            y_hat = model(x)\n",
        "            test_mse_metrics(y_hat, y)\n",
        "            test_mae_metrics(y_hat, y)\n",
        "            counter += 1\n",
        "            if counter >= NUM_TEST_ITER:\n",
        "                break\n",
        "    test_mse = test_mse_metrics.compute()\n",
        "    test_mae = test_mae_metrics.compute()\n",
        "    assert test_mse < 5E-4\n",
        "    assert test_mae < 2E-2\n",
        "\n",
        "def test_earthnet():\n",
        "    data_channels = 4\n",
        "    pretrained_ckpt_name = \"earthformer_earthnet2021.pt\"\n",
        "    test_data_name = \"unittest_earthnet2021_data_bs1_idx0to31.pt\"\n",
        "    s3_download_unittest_data(data_name=test_data_name)\n",
        "    test_data_path = os.path.join(test_data_dir, test_data_name)\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    # Load pretrained model\n",
        "    pretrained_cfg_path = os.path.join(cfg.root_dir, \"scripts\", \"cuboid_transformer\", \"earthnet_w_meso\", \"earthformer_earthnet_v1.yaml\")\n",
        "    pretrained_cfg = OmegaConf.load(open(pretrained_cfg_path, \"r\"))\n",
        "    model = config_cuboid_transformer(\n",
        "        cfg=pretrained_cfg,\n",
        "        model_type=\"CuboidTransformerAuxModel\").to(device)\n",
        "    model.eval()\n",
        "\n",
        "    if not os.path.exists(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name)):\n",
        "        s3_download_pretrained_ckpt(ckpt_name=pretrained_ckpt_name,\n",
        "                                    save_dir=cfg.pretrained_checkpoints_dir,\n",
        "                                    exist_ok=False)\n",
        "    state_dict = torch.load(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name),\n",
        "                            map_location=device)\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(state_dict=state_dict, strict=False)\n",
        "    assert len(missing_keys) == 0, f\"missing_keys {missing_keys} when loading pretrained state_dict.\"\n",
        "    assert len(unexpected_keys) == 0, f\"missing_keys {unexpected_keys} when loading pretrained state_dict.\"\n",
        "    # Test on EarthNet2021 test\n",
        "    layout_cfg = pretrained_cfg.layout\n",
        "    in_slice, out_slice = layout_to_in_out_slice(layout=layout_cfg.layout,\n",
        "                                                 in_len=layout_cfg.in_len,\n",
        "                                                 out_len=layout_cfg.out_len)\n",
        "    test_mse_metrics = torchmetrics.MeanSquaredError().to(device)\n",
        "    test_mae_metrics = torchmetrics.MeanAbsoluteError().to(device)\n",
        "    test_data = torch.load(test_data_path)\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_data:\n",
        "            highresdynamic = batch[\"highresdynamic\"].to(device)\n",
        "            seq = highresdynamic[..., :data_channels]\n",
        "            print(seq.shape)\n",
        "            # mask from dataloader: 1 for mask and 0 for non-masked\n",
        "            mask = highresdynamic[..., data_channels: data_channels + 1][out_slice]\n",
        "            in_seq = seq[in_slice]\n",
        "            target_seq = seq[out_slice]\n",
        "            # process aux data\n",
        "            highresstatic = batch[\"highresstatic\"].to(device)  # (b c h w)\n",
        "            mesodynamic = batch[\"mesodynamic\"].to(device)  # (b t h w c)\n",
        "            mesostatic = batch[\"mesostatic\"].to(device)  # (b c h w)\n",
        "            mesodynamic_interp = rearrange(mesodynamic,\n",
        "                                           \"b t h w c -> b c t h w\")\n",
        "            mesodynamic_interp = F.interpolate(mesodynamic_interp,\n",
        "                                               size=(layout_cfg.in_len + layout_cfg.out_len,\n",
        "                                                     layout_cfg.img_height,\n",
        "                                                     layout_cfg.img_width),\n",
        "                                               mode=\"nearest\")\n",
        "            highresstatic_interp = rearrange(highresstatic,\n",
        "                                             \"b c h w -> b c 1 h w\")\n",
        "            highresstatic_interp = F.interpolate(highresstatic_interp,\n",
        "                                                 size=(layout_cfg.in_len + layout_cfg.out_len,\n",
        "                                                       layout_cfg.img_height,\n",
        "                                                       layout_cfg.img_width),\n",
        "                                                 mode=\"nearest\")\n",
        "            mesostatic_interp = rearrange(mesostatic,\n",
        "                                          \"b c h w -> b c 1 h w\")\n",
        "            mesostatic_interp = F.interpolate(mesostatic_interp,\n",
        "                                              size=(layout_cfg.in_len + layout_cfg.out_len,\n",
        "                                                    layout_cfg.img_height,\n",
        "                                                    layout_cfg.img_width),\n",
        "                                              mode=\"nearest\")\n",
        "            aux_data = torch.cat((highresstatic_interp, mesodynamic_interp, mesostatic_interp),\n",
        "                                 dim=1)\n",
        "            aux_data = rearrange(aux_data,\n",
        "                                 \"b c t h w -> b t h w c\")\n",
        "            pred_seq = model(in_seq, aux_data[in_slice], aux_data[out_slice])\n",
        "            test_mse_metrics(pred_seq * (1 - mask), target_seq * (1 - mask))\n",
        "            test_mae_metrics(pred_seq * (1 - mask), target_seq * (1 - mask))\n",
        "            counter += 1\n",
        "            if counter >= NUM_TEST_ITER:\n",
        "                break\n",
        "    test_mse = test_mse_metrics.compute()\n",
        "    test_mae = test_mae_metrics.compute()\n",
        "    assert test_mse < 5E-4\n",
        "    assert test_mae < 1E-2"
      ],
      "metadata": {
        "id": "7kBTPRe9-Pjo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # trying to run some parts to understand what is going on\n",
        "    pretrained_ckpt_name = \"earthformer_sevir.pt\"\n",
        "    test_data_name = \"unittest_sevir_data_bs1_idx0to31.pt\"\n",
        "    s3_download_unittest_data(data_name=test_data_name)\n",
        "    test_data_path = os.path.join(test_data_dir, test_data_name)\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    # Load pretrained model\n",
        "    pretrained_cfg_path = os.path.join(cfg.root_dir, \"scripts\", \"cuboid_transformer\", \"sevir\", \"earthformer_sevir_v1.yaml\")\n",
        "    pretrained_cfg = OmegaConf.load(open(pretrained_cfg_path, \"r\"))\n",
        "    model = config_cuboid_transformer(\n",
        "        cfg=pretrained_cfg,\n",
        "        model_type=\"CuboidTransformerModel\").to(device)\n",
        "    model.eval()"
      ],
      "metadata": {
        "id": "Y1fKkfxuCFQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model # holds all layers of the model"
      ],
      "metadata": {
        "id": "MiR1OROcdGqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    if not os.path.exists(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name)):\n",
        "        s3_download_pretrained_ckpt(ckpt_name=pretrained_ckpt_name,\n",
        "                                    save_dir=cfg.pretrained_checkpoints_dir,\n",
        "                                    exist_ok=False)\n",
        "    state_dict = torch.load(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name),\n",
        "                            map_location=device)\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(state_dict=state_dict, strict=False)\n",
        "    assert len(missing_keys) == 0, f\"missing_keys {missing_keys} when loading pretrained state_dict.\"\n",
        "    assert len(unexpected_keys) == 0, f\"missing_keys {unexpected_keys} when loading pretrained state_dict.\"\n",
        "    # Test on SEVIR test\n",
        "    layout_cfg = pretrained_cfg.layout\n",
        "    in_slice, out_slice = layout_to_in_out_slice(layout=layout_cfg.layout,\n",
        "                                                 in_len=layout_cfg.in_len,\n",
        "                                                 out_len=layout_cfg.out_len)\n",
        "    test_mse_metrics = torchmetrics.MeanSquaredError().to(device)\n",
        "    test_mae_metrics = torchmetrics.MeanAbsoluteError().to(device)\n",
        "    test_data = torch.load(test_data_path)\n",
        "    counter = 0"
      ],
      "metadata": {
        "id": "wyQL2jlHddX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layout_cfg"
      ],
      "metadata": {
        "id": "8-GVWgPoeDDp",
        "outputId": "b9a5157b-5188-4337-c7f0-3225f6987bc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'in_len': 13, 'out_len': 12, 'layout': 'NTHWC'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data # this is data!!! :O how can we see the pictures?!"
      ],
      "metadata": {
        "id": "ybaVZHCWeIWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspecting RAW sevir data set"
      ],
      "metadata": {
        "id": "5SttUm1dqmHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the files... I want to download a small amount and try the inferance on them.\n",
        "# fixing the <object> problem with https://stackoverflow.com/questions/69666943/aws-cli-returns-python-objects-instead-of-regular-output\n",
        "!aws s3 ls --no-sign-request s3://sevir/data/vil --recursive --human-readable --region us-west-2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZJKu9m1ia6X",
        "outputId": "9a572d1a-13c6-4faf-8303-1c269bad9366"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020-04-15 02:49:50    9.7 GiB data/vil/2017/SEVIR_VIL_RANDOMEVENTS_2017_0501_0831.h5\n",
            "2020-04-15 02:49:50   12.8 GiB data/vil/2017/SEVIR_VIL_RANDOMEVENTS_2017_0901_1231.h5\n",
            "2020-04-15 02:49:57    1.3 GiB data/vil/2017/SEVIR_VIL_STORMEVENTS_2017_0101_0630.h5\n",
            "2020-04-15 02:50:00    4.6 GiB data/vil/2017/SEVIR_VIL_STORMEVENTS_2017_0701_1231.h5\n",
            "2020-04-15 02:50:09   11.5 GiB data/vil/2018/SEVIR_VIL_RANDOMEVENTS_2018_0101_0430.h5\n",
            "2020-04-15 02:52:12   15.9 GiB data/vil/2018/SEVIR_VIL_RANDOMEVENTS_2018_0501_0831.h5\n",
            "2020-04-15 02:58:05   15.1 GiB data/vil/2018/SEVIR_VIL_RANDOMEVENTS_2018_0901_1231.h5\n",
            "2020-04-15 03:06:49    5.3 GiB data/vil/2018/SEVIR_VIL_STORMEVENTS_2018_0101_0630.h5\n",
            "2020-04-15 03:10:18    5.7 GiB data/vil/2018/SEVIR_VIL_STORMEVENTS_2018_0701_1231.h5\n",
            "2020-04-15 18:28:01   15.2 GiB data/vil/2019/SEVIR_VIL_RANDOMEVENTS_2019_0101_0430.h5\n",
            "2020-04-15 18:28:02   15.6 GiB data/vil/2019/SEVIR_VIL_RANDOMEVENTS_2019_0501_0831.h5\n",
            "2020-04-15 18:28:02   15.1 GiB data/vil/2019/SEVIR_VIL_RANDOMEVENTS_2019_0901_1231.h5\n",
            "2020-04-15 03:20:30    5.7 GiB data/vil/2019/SEVIR_VIL_STORMEVENTS_2019_0101_0630.h5\n",
            "2020-04-15 03:24:48    3.6 GiB data/vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets download only one of the h5 files and the CATALOG file\n",
        "!aws s3 cp --no-sign-request --region us-west-2 s3://sevir/data/vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5 /content/earth-forecasting-transformer/src/earthformer/datasets/sevir/data/vil\n",
        "!aws s3 cp --no-sign-request --region us-west-2 s3://sevir/CATALOG.csv /content/earth-forecasting-transformer/src/earthformer/datasets/sevir/CATALOG.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZY9FtifmMrJ",
        "outputId": "cc7a7fd9-ef37-4cbf-b720-110c141ee87e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download: s3://sevir/data/vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5 to earthformer/datasets/sevir/data/vil/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5\n",
            "download: s3://sevir/CATALOG.csv to earthformer/datasets/sevir/CATALOG.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from src/earthformer/datasets/sevir/sevir_dataloader.py, read h5 file\n",
        "import h5py\n",
        "h5py.File(r'/content/earth-forecasting-transformer/src/earthformer/datasets/sevir/data/vil/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5', 'r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcMdAclt17uv",
        "outputId": "7deab48b-963b-4058-f301-10c076614790"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<HDF5 file \"SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5\" (mode r)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is complex to run it like this, trying to run the actual code\n",
        "%cd  /content/earth-forecasting-transformer/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc21YW-38s4K",
        "outputId": "7b00dbe9-1013-4221-b0c4-9620f4642dd3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/earth-forecasting-transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "src/earthformer/datasets/sevir/sevir_torch_wrap.py"
      ],
      "metadata": {
        "id": "PkOT87ZR98Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Union, Dict, Sequence, Tuple, List\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
        "from pytorch_lightning import LightningDataModule\n",
        "from src.earthformer.config import cfg\n",
        "from src.earthformer.datasets.sevir.sevir_dataloader import SEVIRDataLoader\n",
        "\n",
        "\n",
        "class SEVIRTorchDataset(TorchDataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 seq_len: int = 25,\n",
        "                 raw_seq_len: int = 49,\n",
        "                 sample_mode: str = \"sequent\",\n",
        "                 stride: int = 12,\n",
        "                 batch_size: int = 1,\n",
        "                 layout: str = \"NHWT\",\n",
        "                 num_shard: int = 1,\n",
        "                 rank: int = 0,\n",
        "                 split_mode: str = \"uneven\",\n",
        "                 sevir_catalog: Union[str, pd.DataFrame] = None,\n",
        "                 sevir_data_dir: str = None,\n",
        "                 start_date: datetime.datetime = None,\n",
        "                 end_date: datetime.datetime = None,\n",
        "                 datetime_filter = None,\n",
        "                 catalog_filter = \"default\",\n",
        "                 shuffle: bool = False,\n",
        "                 shuffle_seed: int = 1,\n",
        "                 output_type = np.float32,\n",
        "                 preprocess: bool = True,\n",
        "                 rescale_method: str = \"01\",\n",
        "                 verbose: bool = False):\n",
        "        super(SEVIRTorchDataset, self).__init__()\n",
        "        self.layout = layout\n",
        "        self.sevir_dataloader = SEVIRDataLoader(\n",
        "            data_types=[\"vil\", ],\n",
        "            seq_len=seq_len,\n",
        "            raw_seq_len=raw_seq_len,\n",
        "            sample_mode=sample_mode,\n",
        "            stride=stride,\n",
        "            batch_size=batch_size,\n",
        "            layout=layout,\n",
        "            num_shard=num_shard,\n",
        "            rank=rank,\n",
        "            split_mode=split_mode,\n",
        "            sevir_catalog=sevir_catalog,\n",
        "            sevir_data_dir=sevir_data_dir,\n",
        "            start_date=start_date,\n",
        "            end_date=end_date,\n",
        "            datetime_filter=datetime_filter,\n",
        "            catalog_filter=catalog_filter,\n",
        "            shuffle=shuffle,\n",
        "            shuffle_seed=shuffle_seed,\n",
        "            output_type=output_type,\n",
        "            preprocess=preprocess,\n",
        "            rescale_method=rescale_method,\n",
        "            downsample_dict=None,\n",
        "            verbose=verbose)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data_dict = self.sevir_dataloader._idx_sample(index=index)\n",
        "        return data_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.sevir_dataloader.__len__()\n",
        "\n",
        "    def collate_fn(self, data_dict_list):\n",
        "        r\"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        data_dict_list:  list[Dict[str, torch.Tensor]]\n",
        "        Returns\n",
        "        -------\n",
        "        merged_data: Dict[str, torch.Tensor]\n",
        "            batch_size = len(data_dict_list) * data_dict[\"key\"].batch_size\n",
        "        \"\"\"\n",
        "        batch_dim = self.layout.find('N')\n",
        "        data_list_dict = {\n",
        "            key: [data_dict[key]\n",
        "                  for data_dict in data_dict_list]\n",
        "            for key in data_dict_list[0]}\n",
        "        # TODO: key \"mask\" is not handled. Temporally fine since this func is not used\n",
        "        data_list_dict.pop(\"mask\", None)\n",
        "        merged_dict = {\n",
        "            key: torch.cat(data_list,\n",
        "                           dim=batch_dim)\n",
        "            for key, data_list in data_list_dict.items()}\n",
        "        merged_dict[\"mask\"] = None\n",
        "        return merged_dict\n",
        "\n",
        "    def get_torch_dataloader(self,\n",
        "                             outer_batch_size=1,\n",
        "                             collate_fn=None,\n",
        "                             num_workers=1):\n",
        "        # TODO: num_workers > 1\n",
        "        r\"\"\"\n",
        "        We set the batch_size in Dataset by default, so outer_batch_size should be 1.\n",
        "        In this case, not using `collate_fn` can save time.\n",
        "        \"\"\"\n",
        "        if outer_batch_size == 1:\n",
        "            collate_fn = lambda x:x[0]\n",
        "        else:\n",
        "            if collate_fn is None:\n",
        "                collate_fn = self.collate_fn\n",
        "        dataloader = DataLoader(\n",
        "            dataset=self,\n",
        "            batch_size=outer_batch_size,\n",
        "            collate_fn=collate_fn,\n",
        "            num_workers=num_workers)\n",
        "        return dataloader\n",
        "\n",
        "\n",
        "def check_aws():\n",
        "    r\"\"\"\n",
        "    Check if aws cli is installed.\n",
        "    \"\"\"\n",
        "    if os.system(\"which aws\") != 0:\n",
        "        raise RuntimeError(\"AWS CLI is not installed! Please install it first. See https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\")\n",
        "\n",
        "\n",
        "def download_SEVIR(save_dir=None):\n",
        "    r\"\"\"\n",
        "    Downloaded dataset is saved in save_dir/sevir\n",
        "    \"\"\"\n",
        "\n",
        "    check_aws()\n",
        "\n",
        "    if save_dir is None:\n",
        "        save_dir = cfg.datasets_dir\n",
        "    sevir_dir = os.path.join(save_dir, \"sevir\")\n",
        "    if os.path.exists(sevir_dir):\n",
        "        raise FileExistsError(f\"Path to save SEVIR dataset {sevir_dir} already exists!\")\n",
        "    else:\n",
        "        os.makedirs(sevir_dir)\n",
        "        os.system(f\"aws s3 cp --region us-west-2 --no-sign-request s3://sevir/CATALOG.csv \"\n",
        "                  f\"{os.path.join(sevir_dir, 'CATALOG.csv')}\")\n",
        "        os.system(f\"aws s3 cp --region us-west-2 --no-sign-request s3://sevir/data/vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5 \"\n",
        "                  f\"{os.path.join(sevir_dir, 'data', 'vil', '2019', 'SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5')}\")\n",
        "\n",
        "class SEVIRLightningDataModule(LightningDataModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 seq_len: int = 25,\n",
        "                 sample_mode: str = \"sequent\",\n",
        "                 stride: int = 12,\n",
        "                 batch_size: int = 1,\n",
        "                 layout: str = \"NHWT\",\n",
        "                 output_type = np.float32,\n",
        "                 preprocess: bool = True,\n",
        "                 rescale_method: str = \"01\",\n",
        "                 verbose: bool = False,\n",
        "                 # datamodule_only\n",
        "                 dataset_name: str = \"sevir\",\n",
        "                 start_date: Tuple[int] = None,\n",
        "                 train_val_split_date: Tuple[int] = (2019, 1, 1),\n",
        "                 train_test_split_date: Tuple[int] = (2019, 6, 1),\n",
        "                 end_date: Tuple[int] = None,\n",
        "                 num_workers: int = 1,\n",
        "                 ):\n",
        "        super(SEVIRLightningDataModule, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.sample_mode = sample_mode\n",
        "        self.stride = stride\n",
        "        self.batch_size = batch_size\n",
        "        self.layout = layout\n",
        "        self.output_type = output_type\n",
        "        self.preprocess = preprocess\n",
        "        self.rescale_method = rescale_method\n",
        "        self.verbose = verbose\n",
        "        self.num_workers = num_workers\n",
        "        if dataset_name == \"sevir\":\n",
        "            sevir_root_dir = os.path.join(cfg.datasets_dir, \"sevir\")\n",
        "            catalog_path = os.path.join(sevir_root_dir, \"CATALOG.csv\")\n",
        "            raw_data_dir = os.path.join(sevir_root_dir, \"data\")\n",
        "            raw_seq_len = 49\n",
        "            interval_real_time = 5\n",
        "            img_height = 384\n",
        "            img_width = 384\n",
        "        elif dataset_name == \"sevir_lr\":\n",
        "            sevir_root_dir = os.path.join(cfg.datasets_dir, \"sevir_lr\")\n",
        "            catalog_path = os.path.join(sevir_root_dir, \"CATALOG.csv\")\n",
        "            raw_data_dir = os.path.join(sevir_root_dir, \"data\")\n",
        "            raw_seq_len = 25\n",
        "            interval_real_time = 10\n",
        "            img_height = 128\n",
        "            img_width = 128\n",
        "        else:\n",
        "            raise ValueError(f\"Wrong dataset name {dataset_name}. Must be 'sevir' or 'sevir_lr'.\")\n",
        "        self.dataset_name = dataset_name\n",
        "        self.sevir_root_dir = sevir_root_dir\n",
        "        self.catalog_path = catalog_path\n",
        "        self.raw_data_dir = raw_data_dir\n",
        "        self.raw_seq_len = raw_seq_len\n",
        "        self.interval_real_time = interval_real_time\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        # train val test split\n",
        "        self.start_date = datetime.datetime(*start_date) \\\n",
        "            if start_date is not None else None\n",
        "        self.train_val_split_date = datetime.datetime(*train_val_split_date)\n",
        "        self.train_test_split_date = datetime.datetime(*train_test_split_date)\n",
        "        self.end_date = datetime.datetime(*end_date) \\\n",
        "            if end_date is not None else None\n",
        "\n",
        "    def prepare_data(self) -> None:\n",
        "        if os.path.exists(self.sevir_root_dir):\n",
        "            # Further check\n",
        "            assert os.path.exists(self.catalog_path), f\"CATALOG.csv not found! Should be located at {self.catalog_path}\"\n",
        "            assert os.path.exists(self.raw_data_dir), f\"SEVIR data not found! Should be located at {self.raw_data_dir}\"\n",
        "        else:\n",
        "            if self.dataset_name == \"sevir\":\n",
        "                download_SEVIR()\n",
        "            else:  # \"sevir_lr\"\n",
        "                raise NotImplementedError\n",
        "\n",
        "    def setup(self, stage = None) -> None:\n",
        "        self.sevir_train = None\n",
        "        self.sevir_val = None\n",
        "        self.sevir_test = None\n",
        "        self.sevir_predict = SEVIRTorchDataset(\n",
        "            sevir_catalog=self.catalog_path,\n",
        "            sevir_data_dir=self.raw_data_dir,\n",
        "            raw_seq_len=self.raw_seq_len,\n",
        "            split_mode=\"uneven\",\n",
        "            shuffle=False,\n",
        "            seq_len=self.seq_len,\n",
        "            stride=self.stride,\n",
        "            sample_mode=self.sample_mode,\n",
        "            batch_size=self.batch_size,\n",
        "            layout=self.layout,\n",
        "            num_shard=1, rank=0,\n",
        "            start_date=datetime.datetime(*(2019, 8, 1)), #editing start and end date to match only the data I downloaded\n",
        "            end_date=datetime.datetime(*(2019, 9, 1)),\n",
        "            output_type=self.output_type,\n",
        "            preprocess=self.preprocess,\n",
        "            rescale_method=self.rescale_method,\n",
        "            verbose=self.verbose,)\n",
        "        \n",
        "    def train_dataloader(self):\n",
        "        return self.sevir_train.get_torch_dataloader(num_workers=self.num_workers)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.sevir_val.get_torch_dataloader(num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self.sevir_test.get_torch_dataloader(num_workers=self.num_workers)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return self.sevir_predict.get_torch_dataloader(num_workers=self.num_workers)\n",
        "\n",
        "    @property\n",
        "    def num_train_samples(self):\n",
        "        return len(self.sevir_train)\n",
        "\n",
        "    @property\n",
        "    def num_val_samples(self):\n",
        "        return len(self.sevir_val)\n",
        "\n",
        "    @property\n",
        "    def num_test_samples(self):\n",
        "        return len(self.sevir_test)"
      ],
      "metadata": {
        "id": "xpwS03m2jBTo"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seems like what loads the data\n",
        "sevir = SEVIRLightningDataModule()"
      ],
      "metadata": {
        "id": "aO27Xo3vBwl3"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download only one data file! download_SEVIR (make sure the directory does not exists before you run this)\n",
        "download_SEVIR()"
      ],
      "metadata": {
        "id": "ff85jZQLddv4"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from src/earthformer/datasets/sevir/sevir_dataloader.py, read CATALOG, I will try to edit the catalog such it will have only the chosen file\n",
        "import pandas as pd\n",
        "sevir_dir = os.path.join(cfg.datasets_dir, \"sevir\")\n",
        "catalog = pd.read_csv(os.path.join(sevir_dir, 'CATALOG.csv'), parse_dates=['time_utc'], low_memory=False)\n",
        "catalog = catalog[catalog['file_name'] == os.path.join('vil', '2019', 'SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5')]\n",
        "catalog.to_csv(os.path.join(sevir_dir, 'CATALOG.csv'))"
      ],
      "metadata": {
        "id": "2t1YQllsiTWY"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catalog = pd.read_csv(os.path.join(sevir_dir, 'CATALOG.csv'), parse_dates=['time_utc'], low_memory=False)\n",
        "catalog"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mxn9YK0EkP2o",
        "outputId": "bbf43e32-58f8-465e-9606-df4bf3958bcb"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0       id                                         file_name  \\\n",
              "0         49664  S851839  vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5   \n",
              "1         49665  S856840  vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5   \n",
              "2         49666  S853914  vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5   \n",
              "3         49667  S858016  vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5   \n",
              "4         49668  S847132  vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5   \n",
              "..          ...      ...                                               ...   \n",
              "536       50200  S842585  vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5   \n",
              "537       50201  S857334  vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5   \n",
              "538       50202  S857362  vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5   \n",
              "539       50203  S849856  vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5   \n",
              "540       50204  S847595  vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5   \n",
              "\n",
              "     file_index img_type            time_utc  \\\n",
              "0             0      vil 2019-08-18 18:43:00   \n",
              "1             1      vil 2019-09-05 16:37:00   \n",
              "2             2      vil 2019-08-30 06:51:00   \n",
              "3             3      vil 2019-09-20 00:00:00   \n",
              "4             4      vil 2019-08-01 03:00:00   \n",
              "..          ...      ...                 ...   \n",
              "536         536      vil 2019-07-30 20:00:00   \n",
              "537         537      vil 2019-09-14 23:18:00   \n",
              "538         538      vil 2019-09-24 00:25:00   \n",
              "539         539      vil 2019-08-14 23:25:00   \n",
              "540         540      vil 2019-08-18 09:54:00   \n",
              "\n",
              "                                        minute_offsets  episode_id  event_id  \\\n",
              "0    -118:-113:-108:-103:-98:-93:-88:-83:-78:-73:-6...    139205.0  851839.0   \n",
              "1    -122:-117:-112:-107:-102:-97:-92:-87:-82:-77:-...    140548.0  856840.0   \n",
              "2    -121:-116:-111:-106:-101:-96:-91:-86:-81:-76:-...    142225.0  853914.0   \n",
              "3    -120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...    142596.0  858016.0   \n",
              "4    -120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...    140993.0  847132.0   \n",
              "..                                                 ...         ...       ...   \n",
              "536  -120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...    139866.0  842585.0   \n",
              "537  -118:-113:-108:-103:-98:-93:-88:-83:-78:-73:-6...    142879.0  857334.0   \n",
              "538  -120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...    142884.0  857362.0   \n",
              "539  -120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...    141522.0  849856.0   \n",
              "540  -119:-114:-109:-104:-99:-94:-89:-84:-79:-74:-6...    140673.0  847595.0   \n",
              "\n",
              "            event_type  ...  urcrnrlat   urcrnrlon  \\\n",
              "0    Thunderstorm Wind  ...  43.194008  -74.247605   \n",
              "1              Tornado  ...  36.438298  -75.193531   \n",
              "2    Thunderstorm Wind  ...  39.763899  -93.880341   \n",
              "3    Thunderstorm Wind  ...  40.671850  -99.422569   \n",
              "4                 Hail  ...  39.845449  -93.171606   \n",
              "..                 ...  ...        ...         ...   \n",
              "536  Thunderstorm Wind  ...  43.119147  -72.692830   \n",
              "537  Thunderstorm Wind  ...  36.907878  -83.820307   \n",
              "538               Hail  ...  36.628335 -112.537056   \n",
              "539  Thunderstorm Wind  ...  34.427325  -82.160309   \n",
              "540  Thunderstorm Wind  ...  42.789992  -79.172333   \n",
              "\n",
              "                                                  proj  size_x size_y  \\\n",
              "0    +proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...     384    384   \n",
              "1    +proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...     384    384   \n",
              "2    +proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...     384    384   \n",
              "3    +proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...     384    384   \n",
              "4    +proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...     384    384   \n",
              "..                                                 ...     ...    ...   \n",
              "536  +proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...     384    384   \n",
              "537  +proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...     384    384   \n",
              "538  +proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...     384    384   \n",
              "539  +proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...     384    384   \n",
              "540  +proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...     384    384   \n",
              "\n",
              "     height_m   width_m  data_min  data_max  pct_missing  \n",
              "0    384000.0  384000.0       0.0     254.0          0.0  \n",
              "1    384000.0  384000.0       0.0     227.0          0.0  \n",
              "2    384000.0  384000.0       0.0     254.0          0.0  \n",
              "3    384000.0  384000.0       0.0     254.0          0.0  \n",
              "4    384000.0  384000.0       0.0     254.0          0.0  \n",
              "..        ...       ...       ...       ...          ...  \n",
              "536  384000.0  384000.0       0.0     254.0          0.0  \n",
              "537  384000.0  384000.0       0.0     254.0          0.0  \n",
              "538  384000.0  384000.0       0.0     254.0          0.0  \n",
              "539  384000.0  384000.0       0.0     254.0          0.0  \n",
              "540  384000.0  384000.0       0.0     254.0          0.0  \n",
              "\n",
              "[541 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51242047-9ef8-45a4-939f-42dccb62a386\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>file_name</th>\n",
              "      <th>file_index</th>\n",
              "      <th>img_type</th>\n",
              "      <th>time_utc</th>\n",
              "      <th>minute_offsets</th>\n",
              "      <th>episode_id</th>\n",
              "      <th>event_id</th>\n",
              "      <th>event_type</th>\n",
              "      <th>...</th>\n",
              "      <th>urcrnrlat</th>\n",
              "      <th>urcrnrlon</th>\n",
              "      <th>proj</th>\n",
              "      <th>size_x</th>\n",
              "      <th>size_y</th>\n",
              "      <th>height_m</th>\n",
              "      <th>width_m</th>\n",
              "      <th>data_min</th>\n",
              "      <th>data_max</th>\n",
              "      <th>pct_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49664</td>\n",
              "      <td>S851839</td>\n",
              "      <td>vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5</td>\n",
              "      <td>0</td>\n",
              "      <td>vil</td>\n",
              "      <td>2019-08-18 18:43:00</td>\n",
              "      <td>-118:-113:-108:-103:-98:-93:-88:-83:-78:-73:-6...</td>\n",
              "      <td>139205.0</td>\n",
              "      <td>851839.0</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>...</td>\n",
              "      <td>43.194008</td>\n",
              "      <td>-74.247605</td>\n",
              "      <td>+proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...</td>\n",
              "      <td>384</td>\n",
              "      <td>384</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49665</td>\n",
              "      <td>S856840</td>\n",
              "      <td>vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5</td>\n",
              "      <td>1</td>\n",
              "      <td>vil</td>\n",
              "      <td>2019-09-05 16:37:00</td>\n",
              "      <td>-122:-117:-112:-107:-102:-97:-92:-87:-82:-77:-...</td>\n",
              "      <td>140548.0</td>\n",
              "      <td>856840.0</td>\n",
              "      <td>Tornado</td>\n",
              "      <td>...</td>\n",
              "      <td>36.438298</td>\n",
              "      <td>-75.193531</td>\n",
              "      <td>+proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...</td>\n",
              "      <td>384</td>\n",
              "      <td>384</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49666</td>\n",
              "      <td>S853914</td>\n",
              "      <td>vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5</td>\n",
              "      <td>2</td>\n",
              "      <td>vil</td>\n",
              "      <td>2019-08-30 06:51:00</td>\n",
              "      <td>-121:-116:-111:-106:-101:-96:-91:-86:-81:-76:-...</td>\n",
              "      <td>142225.0</td>\n",
              "      <td>853914.0</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>...</td>\n",
              "      <td>39.763899</td>\n",
              "      <td>-93.880341</td>\n",
              "      <td>+proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...</td>\n",
              "      <td>384</td>\n",
              "      <td>384</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>49667</td>\n",
              "      <td>S858016</td>\n",
              "      <td>vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5</td>\n",
              "      <td>3</td>\n",
              "      <td>vil</td>\n",
              "      <td>2019-09-20 00:00:00</td>\n",
              "      <td>-120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...</td>\n",
              "      <td>142596.0</td>\n",
              "      <td>858016.0</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>...</td>\n",
              "      <td>40.671850</td>\n",
              "      <td>-99.422569</td>\n",
              "      <td>+proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...</td>\n",
              "      <td>384</td>\n",
              "      <td>384</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49668</td>\n",
              "      <td>S847132</td>\n",
              "      <td>vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5</td>\n",
              "      <td>4</td>\n",
              "      <td>vil</td>\n",
              "      <td>2019-08-01 03:00:00</td>\n",
              "      <td>-120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...</td>\n",
              "      <td>140993.0</td>\n",
              "      <td>847132.0</td>\n",
              "      <td>Hail</td>\n",
              "      <td>...</td>\n",
              "      <td>39.845449</td>\n",
              "      <td>-93.171606</td>\n",
              "      <td>+proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...</td>\n",
              "      <td>384</td>\n",
              "      <td>384</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>50200</td>\n",
              "      <td>S842585</td>\n",
              "      <td>vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5</td>\n",
              "      <td>536</td>\n",
              "      <td>vil</td>\n",
              "      <td>2019-07-30 20:00:00</td>\n",
              "      <td>-120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...</td>\n",
              "      <td>139866.0</td>\n",
              "      <td>842585.0</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>...</td>\n",
              "      <td>43.119147</td>\n",
              "      <td>-72.692830</td>\n",
              "      <td>+proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...</td>\n",
              "      <td>384</td>\n",
              "      <td>384</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>50201</td>\n",
              "      <td>S857334</td>\n",
              "      <td>vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5</td>\n",
              "      <td>537</td>\n",
              "      <td>vil</td>\n",
              "      <td>2019-09-14 23:18:00</td>\n",
              "      <td>-118:-113:-108:-103:-98:-93:-88:-83:-78:-73:-6...</td>\n",
              "      <td>142879.0</td>\n",
              "      <td>857334.0</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>...</td>\n",
              "      <td>36.907878</td>\n",
              "      <td>-83.820307</td>\n",
              "      <td>+proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...</td>\n",
              "      <td>384</td>\n",
              "      <td>384</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>50202</td>\n",
              "      <td>S857362</td>\n",
              "      <td>vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5</td>\n",
              "      <td>538</td>\n",
              "      <td>vil</td>\n",
              "      <td>2019-09-24 00:25:00</td>\n",
              "      <td>-120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...</td>\n",
              "      <td>142884.0</td>\n",
              "      <td>857362.0</td>\n",
              "      <td>Hail</td>\n",
              "      <td>...</td>\n",
              "      <td>36.628335</td>\n",
              "      <td>-112.537056</td>\n",
              "      <td>+proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...</td>\n",
              "      <td>384</td>\n",
              "      <td>384</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>50203</td>\n",
              "      <td>S849856</td>\n",
              "      <td>vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5</td>\n",
              "      <td>539</td>\n",
              "      <td>vil</td>\n",
              "      <td>2019-08-14 23:25:00</td>\n",
              "      <td>-120:-115:-110:-105:-100:-95:-90:-85:-80:-75:-...</td>\n",
              "      <td>141522.0</td>\n",
              "      <td>849856.0</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>...</td>\n",
              "      <td>34.427325</td>\n",
              "      <td>-82.160309</td>\n",
              "      <td>+proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...</td>\n",
              "      <td>384</td>\n",
              "      <td>384</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>50204</td>\n",
              "      <td>S847595</td>\n",
              "      <td>vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5</td>\n",
              "      <td>540</td>\n",
              "      <td>vil</td>\n",
              "      <td>2019-08-18 09:54:00</td>\n",
              "      <td>-119:-114:-109:-104:-99:-94:-89:-84:-79:-74:-6...</td>\n",
              "      <td>140673.0</td>\n",
              "      <td>847595.0</td>\n",
              "      <td>Thunderstorm Wind</td>\n",
              "      <td>...</td>\n",
              "      <td>42.789992</td>\n",
              "      <td>-79.172333</td>\n",
              "      <td>+proj=laea +lat_0=38 +lon_0=-98 +units=m +a=63...</td>\n",
              "      <td>384</td>\n",
              "      <td>384</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>384000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>541 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51242047-9ef8-45a4-939f-42dccb62a386')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51242047-9ef8-45a4-939f-42dccb62a386 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51242047-9ef8-45a4-939f-42dccb62a386');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sevir.setup() # success!!!"
      ],
      "metadata": {
        "id": "NrpyDWrLB1_N"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sevir.sevir_predict[0] # thats the data! now we need to understand how to visualize it!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz5IuQR0o8U5",
        "outputId": "c51c9f6b-594b-4672-8f99-f0531f608e6b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vil': tensor([[[[0.0196, 0.0157, 0.0157,  ..., 0.0353, 0.0392, 0.0588],\n",
              "           [0.0235, 0.0235, 0.0157,  ..., 0.0314, 0.0627, 0.0588],\n",
              "           [0.0235, 0.0235, 0.0314,  ..., 0.0275, 0.0706, 0.0588],\n",
              "           ...,\n",
              "           [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0118, 0.0118],\n",
              "           [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
              "           [0.0157, 0.0196, 0.0196,  ..., 0.0157, 0.0196, 0.0196]],\n",
              " \n",
              "          [[0.0157, 0.0118, 0.0000,  ..., 0.0314, 0.0353, 0.0549],\n",
              "           [0.0235, 0.0196, 0.0157,  ..., 0.0275, 0.0392, 0.0549],\n",
              "           [0.0235, 0.0196, 0.0314,  ..., 0.0275, 0.0588, 0.0471],\n",
              "           ...,\n",
              "           [0.0196, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0118],\n",
              "           [0.0157, 0.0157, 0.0196,  ..., 0.0157, 0.0157, 0.0118],\n",
              "           [0.0157, 0.0196, 0.0196,  ..., 0.0157, 0.0196, 0.0157]],\n",
              " \n",
              "          [[0.0157, 0.0000, 0.0000,  ..., 0.0275, 0.0235, 0.0275],\n",
              "           [0.0196, 0.0196, 0.0157,  ..., 0.0235, 0.0235, 0.0353],\n",
              "           [0.0196, 0.0196, 0.0157,  ..., 0.0196, 0.0235, 0.0353],\n",
              "           ...,\n",
              "           [0.0196, 0.0157, 0.0157,  ..., 0.0157, 0.0118, 0.0118],\n",
              "           [0.0196, 0.0157, 0.0196,  ..., 0.0157, 0.0118, 0.0118],\n",
              "           [0.0196, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[0.0000, 0.0000, 0.0000,  ..., 0.1451, 0.1765, 0.0627],\n",
              "           [0.0000, 0.0000, 0.0000,  ..., 0.1647, 0.1020, 0.0706],\n",
              "           [0.0000, 0.0000, 0.0078,  ..., 0.1843, 0.1020, 0.0902],\n",
              "           ...,\n",
              "           [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0000, 0.0118],\n",
              "           [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0157],\n",
              "           [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0157, 0.0157]],\n",
              " \n",
              "          [[0.0000, 0.0000, 0.0000,  ..., 0.1529, 0.1804, 0.0667],\n",
              "           [0.0000, 0.0000, 0.0000,  ..., 0.1529, 0.1020, 0.0941],\n",
              "           [0.0000, 0.0000, 0.0078,  ..., 0.1686, 0.1020, 0.0941],\n",
              "           ...,\n",
              "           [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0157],\n",
              "           [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0157, 0.0157],\n",
              "           [0.0118, 0.0118, 0.0118,  ..., 0.0157, 0.0157, 0.0157]],\n",
              " \n",
              "          [[0.0000, 0.0000, 0.0000,  ..., 0.1647, 0.1686, 0.1098],\n",
              "           [0.0000, 0.0000, 0.0000,  ..., 0.1569, 0.1020, 0.1137],\n",
              "           [0.0000, 0.0000, 0.0000,  ..., 0.1490, 0.0941, 0.1137],\n",
              "           ...,\n",
              "           [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0157, 0.0157],\n",
              "           [0.0118, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
              "           [0.0118, 0.0118, 0.0118,  ..., 0.0157, 0.0157, 0.0157]]]])}"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wp3lyuPIrqQa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}