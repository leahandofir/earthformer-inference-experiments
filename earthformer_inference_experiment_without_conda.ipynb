{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfQ8FkCjZj3qC+HLANJUiN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leahandofir/earthformer-inference-experiments/blob/main/earthformer_inference_experiment_without_conda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genral:\n",
        "**The goal** - try to understand what we need to do to run model(x) and get a result. **STILL DID NOT REACHED THAT GOAL**\n",
        "\n",
        "**The structure of the code** - \n",
        "- Train\n",
        "- Test\n",
        "- The architecture of the model - the model recieves an example x and returns prediction y. The model has a function named \"eval\" to turn off behaviors that are relevent in the training process (like dropout and batch normalization), this is realy important to do when inferancing!\n",
        "- Data set - the code that responsible for assamble the raw samples as python data structures. This is a class that usually inhirites from a DataSet class of pytorch. Has __getItem__ method that recieves an index and returns a sample x with that index. Also has a __len__ methos that returns the number of samples in the data set.\n",
        "- Data Loader - wraps the Data set. Has a certain number of workers to concurrantly and efficiently read the data set. Has a queue that always prepare the next mini batch so the usage of the GPU will be efficient. \n",
        "collate_fn - a function that aggragates a batch of samples from the data set loader in a data structure that the model can train on.\n",
        "comment - we want the batch to be as large as possible to has less transitions from the CPU to the GPU.\n",
        "\n",
        "Solving error 21/4/2023:\n",
        "\n",
        "Tried to solve the error `ImportError: cannot import name '_PATH' from 'pytorch_lightning.utilities.types`\n",
        "with some google advices with no success.\n",
        "after that saw this error in the pip outputs:\n",
        "```\n",
        "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
        "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.12.1+cu116 which is incompatible.\n",
        "```\n",
        "also this:\n",
        "```\n",
        "ERROR: pip's dependency resolver does not currently \n",
        "take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
        "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.12.1+cu116 which is incompatible.\n",
        "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.12.1+cu116 which is incompatible.\n",
        "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.12.1+cu116 which is incompatible.\n",
        "```\n",
        "so decided to try and install everything with cuda 11.8 and let pip decide the versions.\n",
        "after that it just worked.\n",
        "general good things to copy from their code:\n",
        "- they use os.path a lot. checking if directories exist, and if not they create them. we need our code to be as little as possible dependent on the machine.\n",
        "- they have utils directory of all the general needed things (like download a given url)\n",
        "\n"
      ],
      "metadata": {
        "id": "NiVbVDm2BsIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependencies"
      ],
      "metadata": {
        "id": "p-MVktqwqevf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# install dependencies\n",
        "pip install --upgrade pip\n",
        "python3 -m pip install torch==2.0.0+cu118 torchvision -f https://download.pytorch.org/whl/torch_stable.html\n",
        "python3 -m pip install \"pytorch_lightning>=1.6.4,<1.8.0\"\n",
        "python3 -m pip install xarray netcdf4 opencv-python\n",
        "git clone https://github.com/amazon-science/earth-forecasting-transformer.git\n",
        "cd earth-forecasting-transformer\n",
        "python3 -m pip install -U -e . --no-build-isolation\n",
        "pip install -v --disable-pip-version-check --no-cache-dir pytorch-extension git+https://github.com/NVIDIA/apex.git"
      ],
      "metadata": {
        "id": "Y_BenJuxzolw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# install aws cli to check out sevir dataset\n",
        "curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
        "unzip awscliv2.zip\n",
        "sudo ./aws/install"
      ],
      "metadata": {
        "id": "kNYJH6W7qIqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# checking the aws cli installation and the size of the sevir dataset\n",
        "aws --version"
      ],
      "metadata": {
        "id": "wXptKGncqPpP",
        "outputId": "a31cfb43-43cb-441c-ad28-f7c6a41106b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aws-cli/1.27.125 Python/3.10.11 Linux/5.10.147+ botocore/1.29.125\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/earth-forecasting-transformer/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySPGQ513z09o",
        "outputId": "387f434a-b864-4d78-cb67-147343cead4b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/earth-forecasting-transformer/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is from tests/unittests/test_pretrained_checkpoints.py:"
      ],
      "metadata": {
        "id": "PADYz1yTpy6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import os\n",
        "from omegaconf import OmegaConf\n",
        "import pytest\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import torchmetrics\n",
        "from einops import rearrange\n",
        "from earthformer.config import cfg\n",
        "from earthformer.utils.checkpoint import s3_download_pretrained_ckpt\n",
        "from earthformer.utils.layout import layout_to_in_out_slice\n",
        "from earthformer.utils.utils import download\n",
        "from earthformer.cuboid_transformer.cuboid_transformer import CuboidTransformerModel\n",
        "from earthformer.cuboid_transformer.cuboid_transformer_unet_dec import CuboidTransformerAuxModel\n",
        "\n",
        "\n",
        "NUM_TEST_ITER = 16  # max = 32 since saved `unittest_data.pt` only contains the first 0 to 31 data entries.\n",
        "test_data_dir = os.path.join(cfg.root_dir, \"tests\", \"unittests\", \"test_pretrained_checkpoints_data\")\n",
        "\n",
        "def s3_download_unittest_data(data_name):\n",
        "    test_data_path = os.path.join(test_data_dir, data_name)\n",
        "    if not os.path.exists(test_data_path):\n",
        "        os.makedirs(test_data_dir, exist_ok=True)\n",
        "        download(url=f\"s3://deep-earth/experiments/earthformer/unittests/{data_name}\", path=test_data_path)\n",
        "\n",
        "\n",
        "def config_cuboid_transformer(cfg, model_type=\"CuboidTransformerModel\"):\n",
        "    model_cfg = OmegaConf.to_object(cfg.model)\n",
        "    num_blocks = len(model_cfg[\"enc_depth\"])\n",
        "    if isinstance(model_cfg[\"self_pattern\"], str):\n",
        "        enc_attn_patterns = [model_cfg.pop(\"self_pattern\")] * num_blocks\n",
        "    else:\n",
        "        enc_attn_patterns = OmegaConf.to_container(model_cfg.pop(\"self_pattern\"))\n",
        "    model_cfg[\"enc_attn_patterns\"] = enc_attn_patterns\n",
        "    if isinstance(model_cfg[\"cross_self_pattern\"], str):\n",
        "        dec_self_attn_patterns = [model_cfg.pop(\"cross_self_pattern\")] * num_blocks\n",
        "    else:\n",
        "        dec_self_attn_patterns = OmegaConf.to_container(model_cfg.pop(\"cross_self_pattern\"))\n",
        "    model_cfg[\"dec_self_attn_patterns\"] = dec_self_attn_patterns\n",
        "    if isinstance(model_cfg[\"cross_pattern\"], str):\n",
        "        dec_cross_attn_patterns = [model_cfg.pop(\"cross_pattern\")] * num_blocks\n",
        "    else:\n",
        "        dec_cross_attn_patterns = OmegaConf.to_container(model_cfg.pop(\"cross_pattern\"))\n",
        "    model_cfg[\"dec_cross_attn_patterns\"] = dec_cross_attn_patterns\n",
        "    if model_type == \"CuboidTransformerModel\":\n",
        "        model = CuboidTransformerModel(**model_cfg)\n",
        "    elif model_type == \"CuboidTransformerAuxModel\":\n",
        "        model = CuboidTransformerAuxModel(**model_cfg)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid model_type {model_type}. Must be 'CuboidTransformerModel' or ''.\")\n",
        "    return model\n",
        "\n",
        "def test_sevir():\n",
        "    pretrained_ckpt_name = \"earthformer_sevir.pt\"\n",
        "    test_data_name = \"unittest_sevir_data_bs1_idx0to31.pt\"\n",
        "    s3_download_unittest_data(data_name=test_data_name)\n",
        "    test_data_path = os.path.join(test_data_dir, test_data_name)\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    # Load pretrained model\n",
        "    pretrained_cfg_path = os.path.join(cfg.root_dir, \"scripts\", \"cuboid_transformer\", \"sevir\", \"earthformer_sevir_v1.yaml\")\n",
        "    pretrained_cfg = OmegaConf.load(open(pretrained_cfg_path, \"r\"))\n",
        "    model = config_cuboid_transformer(\n",
        "        cfg=pretrained_cfg,\n",
        "        model_type=\"CuboidTransformerModel\").to(device)\n",
        "    model.eval()\n",
        "    if not os.path.exists(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name)):\n",
        "        s3_download_pretrained_ckpt(ckpt_name=pretrained_ckpt_name,\n",
        "                                    save_dir=cfg.pretrained_checkpoints_dir,\n",
        "                                    exist_ok=False)\n",
        "    state_dict = torch.load(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name),\n",
        "                            map_location=device)\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(state_dict=state_dict, strict=False)\n",
        "    assert len(missing_keys) == 0, f\"missing_keys {missing_keys} when loading pretrained state_dict.\"\n",
        "    assert len(unexpected_keys) == 0, f\"missing_keys {unexpected_keys} when loading pretrained state_dict.\"\n",
        "    # Test on SEVIR test\n",
        "    layout_cfg = pretrained_cfg.layout\n",
        "    in_slice, out_slice = layout_to_in_out_slice(layout=layout_cfg.layout,\n",
        "                                                 in_len=layout_cfg.in_len,\n",
        "                                                 out_len=layout_cfg.out_len)\n",
        "    test_mse_metrics = torchmetrics.MeanSquaredError().to(device)\n",
        "    test_mae_metrics = torchmetrics.MeanAbsoluteError().to(device)\n",
        "    test_data = torch.load(test_data_path)\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_data:\n",
        "            data_seq = batch['vil'].contiguous().to(device)\n",
        "            x = data_seq[in_slice]\n",
        "            y = data_seq[out_slice]\n",
        "            y_hat = model(x)\n",
        "            test_mse_metrics(y_hat, y)\n",
        "            test_mae_metrics(y_hat, y)\n",
        "            counter += 1\n",
        "            if counter >= NUM_TEST_ITER:\n",
        "                break\n",
        "    test_mse = test_mse_metrics.compute()\n",
        "    test_mae = test_mae_metrics.compute()\n",
        "    assert test_mse < 1E-2\n",
        "    assert test_mae < 5E-2\n",
        "\n",
        "def test_enso():\n",
        "    pretrained_ckpt_name = \"earthformer_icarenso2021.pt\"\n",
        "    test_data_name = \"unittest_icarenso2021_data_bs1_idx0to31.pt\"\n",
        "    s3_download_unittest_data(data_name=test_data_name)\n",
        "    test_data_path = os.path.join(test_data_dir, test_data_name)\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    # Load pretrained model\n",
        "    pretrained_cfg_path = os.path.join(cfg.root_dir, \"scripts\", \"cuboid_transformer\", \"enso\", \"earthformer_enso_v1.yaml\")\n",
        "    pretrained_cfg = OmegaConf.load(open(pretrained_cfg_path, \"r\"))\n",
        "    model = config_cuboid_transformer(\n",
        "        cfg=pretrained_cfg,\n",
        "        model_type=\"CuboidTransformerModel\").to(device)\n",
        "    model.eval()\n",
        "\n",
        "    if not os.path.exists(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name)):\n",
        "        s3_download_pretrained_ckpt(ckpt_name=pretrained_ckpt_name,\n",
        "                                    save_dir=cfg.pretrained_checkpoints_dir,\n",
        "                                    exist_ok=False)\n",
        "    state_dict = torch.load(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name),\n",
        "                            map_location=device)\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(state_dict=state_dict, strict=False)\n",
        "    assert len(missing_keys) == 0, f\"missing_keys {missing_keys} when loading pretrained state_dict.\"\n",
        "    assert len(unexpected_keys) == 0, f\"missing_keys {unexpected_keys} when loading pretrained state_dict.\"\n",
        "    # Test on ENSO test\n",
        "    layout_cfg = pretrained_cfg.layout\n",
        "    in_slice, out_slice = layout_to_in_out_slice(layout=layout_cfg.layout,\n",
        "                                                 in_len=layout_cfg.in_len,\n",
        "                                                 out_len=layout_cfg.out_len)\n",
        "    test_mse_metrics = torchmetrics.MeanSquaredError().to(device)\n",
        "    test_mae_metrics = torchmetrics.MeanAbsoluteError().to(device)\n",
        "    test_data = torch.load(test_data_path)\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_data:\n",
        "            sst_seq, nino_target = batch\n",
        "            data_seq = sst_seq.float().unsqueeze(-1).to(device)\n",
        "            x = data_seq[in_slice]\n",
        "            y = data_seq[out_slice]\n",
        "            y_hat = model(x)\n",
        "            test_mse_metrics(y_hat, y)\n",
        "            test_mae_metrics(y_hat, y)\n",
        "            counter += 1\n",
        "            if counter >= NUM_TEST_ITER:\n",
        "                break\n",
        "    test_mse = test_mse_metrics.compute()\n",
        "    test_mae = test_mae_metrics.compute()\n",
        "    assert test_mse < 5E-4\n",
        "    assert test_mae < 2E-2\n",
        "\n",
        "def test_earthnet():\n",
        "    data_channels = 4\n",
        "    pretrained_ckpt_name = \"earthformer_earthnet2021.pt\"\n",
        "    test_data_name = \"unittest_earthnet2021_data_bs1_idx0to31.pt\"\n",
        "    s3_download_unittest_data(data_name=test_data_name)\n",
        "    test_data_path = os.path.join(test_data_dir, test_data_name)\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    # Load pretrained model\n",
        "    pretrained_cfg_path = os.path.join(cfg.root_dir, \"scripts\", \"cuboid_transformer\", \"earthnet_w_meso\", \"earthformer_earthnet_v1.yaml\")\n",
        "    pretrained_cfg = OmegaConf.load(open(pretrained_cfg_path, \"r\"))\n",
        "    model = config_cuboid_transformer(\n",
        "        cfg=pretrained_cfg,\n",
        "        model_type=\"CuboidTransformerAuxModel\").to(device)\n",
        "    model.eval()\n",
        "\n",
        "    if not os.path.exists(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name)):\n",
        "        s3_download_pretrained_ckpt(ckpt_name=pretrained_ckpt_name,\n",
        "                                    save_dir=cfg.pretrained_checkpoints_dir,\n",
        "                                    exist_ok=False)\n",
        "    state_dict = torch.load(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name),\n",
        "                            map_location=device)\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(state_dict=state_dict, strict=False)\n",
        "    assert len(missing_keys) == 0, f\"missing_keys {missing_keys} when loading pretrained state_dict.\"\n",
        "    assert len(unexpected_keys) == 0, f\"missing_keys {unexpected_keys} when loading pretrained state_dict.\"\n",
        "    # Test on EarthNet2021 test\n",
        "    layout_cfg = pretrained_cfg.layout\n",
        "    in_slice, out_slice = layout_to_in_out_slice(layout=layout_cfg.layout,\n",
        "                                                 in_len=layout_cfg.in_len,\n",
        "                                                 out_len=layout_cfg.out_len)\n",
        "    test_mse_metrics = torchmetrics.MeanSquaredError().to(device)\n",
        "    test_mae_metrics = torchmetrics.MeanAbsoluteError().to(device)\n",
        "    test_data = torch.load(test_data_path)\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_data:\n",
        "            highresdynamic = batch[\"highresdynamic\"].to(device)\n",
        "            seq = highresdynamic[..., :data_channels]\n",
        "            print(seq.shape)\n",
        "            # mask from dataloader: 1 for mask and 0 for non-masked\n",
        "            mask = highresdynamic[..., data_channels: data_channels + 1][out_slice]\n",
        "            in_seq = seq[in_slice]\n",
        "            target_seq = seq[out_slice]\n",
        "            # process aux data\n",
        "            highresstatic = batch[\"highresstatic\"].to(device)  # (b c h w)\n",
        "            mesodynamic = batch[\"mesodynamic\"].to(device)  # (b t h w c)\n",
        "            mesostatic = batch[\"mesostatic\"].to(device)  # (b c h w)\n",
        "            mesodynamic_interp = rearrange(mesodynamic,\n",
        "                                           \"b t h w c -> b c t h w\")\n",
        "            mesodynamic_interp = F.interpolate(mesodynamic_interp,\n",
        "                                               size=(layout_cfg.in_len + layout_cfg.out_len,\n",
        "                                                     layout_cfg.img_height,\n",
        "                                                     layout_cfg.img_width),\n",
        "                                               mode=\"nearest\")\n",
        "            highresstatic_interp = rearrange(highresstatic,\n",
        "                                             \"b c h w -> b c 1 h w\")\n",
        "            highresstatic_interp = F.interpolate(highresstatic_interp,\n",
        "                                                 size=(layout_cfg.in_len + layout_cfg.out_len,\n",
        "                                                       layout_cfg.img_height,\n",
        "                                                       layout_cfg.img_width),\n",
        "                                                 mode=\"nearest\")\n",
        "            mesostatic_interp = rearrange(mesostatic,\n",
        "                                          \"b c h w -> b c 1 h w\")\n",
        "            mesostatic_interp = F.interpolate(mesostatic_interp,\n",
        "                                              size=(layout_cfg.in_len + layout_cfg.out_len,\n",
        "                                                    layout_cfg.img_height,\n",
        "                                                    layout_cfg.img_width),\n",
        "                                              mode=\"nearest\")\n",
        "            aux_data = torch.cat((highresstatic_interp, mesodynamic_interp, mesostatic_interp),\n",
        "                                 dim=1)\n",
        "            aux_data = rearrange(aux_data,\n",
        "                                 \"b c t h w -> b t h w c\")\n",
        "            pred_seq = model(in_seq, aux_data[in_slice], aux_data[out_slice])\n",
        "            test_mse_metrics(pred_seq * (1 - mask), target_seq * (1 - mask))\n",
        "            test_mae_metrics(pred_seq * (1 - mask), target_seq * (1 - mask))\n",
        "            counter += 1\n",
        "            if counter >= NUM_TEST_ITER:\n",
        "                break\n",
        "    test_mse = test_mse_metrics.compute()\n",
        "    test_mae = test_mae_metrics.compute()\n",
        "    assert test_mse < 5E-4\n",
        "    assert test_mae < 1E-2"
      ],
      "metadata": {
        "id": "7kBTPRe9-Pjo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # trying to run some parts to understand what is going on\n",
        "    pretrained_ckpt_name = \"earthformer_sevir.pt\"\n",
        "    test_data_name = \"unittest_sevir_data_bs1_idx0to31.pt\"\n",
        "    s3_download_unittest_data(data_name=test_data_name)\n",
        "    test_data_path = os.path.join(test_data_dir, test_data_name)\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    # Load pretrained model\n",
        "    pretrained_cfg_path = os.path.join(cfg.root_dir, \"scripts\", \"cuboid_transformer\", \"sevir\", \"earthformer_sevir_v1.yaml\")\n",
        "    pretrained_cfg = OmegaConf.load(open(pretrained_cfg_path, \"r\"))\n",
        "    model = config_cuboid_transformer(\n",
        "        cfg=pretrained_cfg,\n",
        "        model_type=\"CuboidTransformerModel\").to(device)\n",
        "    model.eval()"
      ],
      "metadata": {
        "id": "Y1fKkfxuCFQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model # holds all layers of the model"
      ],
      "metadata": {
        "id": "MiR1OROcdGqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    if not os.path.exists(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name)):\n",
        "        s3_download_pretrained_ckpt(ckpt_name=pretrained_ckpt_name,\n",
        "                                    save_dir=cfg.pretrained_checkpoints_dir,\n",
        "                                    exist_ok=False)\n",
        "    state_dict = torch.load(os.path.join(cfg.pretrained_checkpoints_dir, pretrained_ckpt_name),\n",
        "                            map_location=device)\n",
        "    missing_keys, unexpected_keys = model.load_state_dict(state_dict=state_dict, strict=False)\n",
        "    assert len(missing_keys) == 0, f\"missing_keys {missing_keys} when loading pretrained state_dict.\"\n",
        "    assert len(unexpected_keys) == 0, f\"missing_keys {unexpected_keys} when loading pretrained state_dict.\"\n",
        "    # Test on SEVIR test\n",
        "    layout_cfg = pretrained_cfg.layout\n",
        "    in_slice, out_slice = layout_to_in_out_slice(layout=layout_cfg.layout,\n",
        "                                                 in_len=layout_cfg.in_len,\n",
        "                                                 out_len=layout_cfg.out_len)\n",
        "    test_mse_metrics = torchmetrics.MeanSquaredError().to(device)\n",
        "    test_mae_metrics = torchmetrics.MeanAbsoluteError().to(device)\n",
        "    test_data = torch.load(test_data_path)\n",
        "    counter = 0"
      ],
      "metadata": {
        "id": "wyQL2jlHddX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layout_cfg"
      ],
      "metadata": {
        "id": "8-GVWgPoeDDp",
        "outputId": "b9a5157b-5188-4337-c7f0-3225f6987bc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'in_len': 13, 'out_len': 12, 'layout': 'NTHWC'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data # this is data!!! :O how can we see the pictures?!"
      ],
      "metadata": {
        "id": "ybaVZHCWeIWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspecting RAW sevir data set"
      ],
      "metadata": {
        "id": "5SttUm1dqmHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the files... I want to download a small amount and try the inferance on them.\n",
        "!aws s3 ls --no-sign-request s3://sevir/data/vil --recursive --human-readable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZJKu9m1ia6X",
        "outputId": "f4d880b5-2783-4db2-af07-6b059bc2fe02"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020-04-15 02:49:50    9.7 GiB data/vil/2017/SEVIR_VIL_RANDOMEVENTS_2017_0501_0831.h5\n",
            "2020-04-15 02:49:50   12.8 GiB data/vil/2017/SEVIR_VIL_RANDOMEVENTS_2017_0901_1231.h5\n",
            "2020-04-15 02:49:57    1.3 GiB data/vil/2017/SEVIR_VIL_STORMEVENTS_2017_0101_0630.h5\n",
            "2020-04-15 02:50:00    4.6 GiB data/vil/2017/SEVIR_VIL_STORMEVENTS_2017_0701_1231.h5\n",
            "2020-04-15 02:50:09   11.5 GiB data/vil/2018/SEVIR_VIL_RANDOMEVENTS_2018_0101_0430.h5\n",
            "2020-04-15 02:52:12   15.9 GiB data/vil/2018/SEVIR_VIL_RANDOMEVENTS_2018_0501_0831.h5\n",
            "2020-04-15 02:58:05   15.1 GiB data/vil/2018/SEVIR_VIL_RANDOMEVENTS_2018_0901_1231.h5\n",
            "2020-04-15 03:06:49    5.3 GiB data/vil/2018/SEVIR_VIL_STORMEVENTS_2018_0101_0630.h5\n",
            "2020-04-15 03:10:18    5.7 GiB data/vil/2018/SEVIR_VIL_STORMEVENTS_2018_0701_1231.h5\n",
            "2020-04-15 18:28:01   15.2 GiB data/vil/2019/SEVIR_VIL_RANDOMEVENTS_2019_0101_0430.h5\n",
            "2020-04-15 18:28:02   15.6 GiB data/vil/2019/SEVIR_VIL_RANDOMEVENTS_2019_0501_0831.h5\n",
            "2020-04-15 18:28:02   15.1 GiB data/vil/2019/SEVIR_VIL_RANDOMEVENTS_2019_0901_1231.h5\n",
            "2020-04-15 03:20:30    5.7 GiB data/vil/2019/SEVIR_VIL_STORMEVENTS_2019_0101_0630.h5\n",
            "2020-04-15 03:24:48    3.6 GiB data/vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets download only one of the h5 files\n",
        "!aws s3 cp --no-sign-request --recursive s3://sevir/data/vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZY9FtifmMrJ",
        "outputId": "0c1948bb-cc0c-4dce-e670-fe92fd3f51c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: \rNote: AWS CLI version 2, the latest major version of the AWS CLI, is now stable and recommended for general use. For more information, see the AWS CLI version 2 installation instructions at: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html\n",
            "\n",
            "usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\n",
            "To see help text, you can run:\n",
            "\n",
            "  aws help\n",
            "  aws <command> help\n",
            "  aws <command> <subcommand> help\n",
            "aws: error: the following arguments are required: paths\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Union, Dict, Sequence, Tuple, List\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
        "from pytorch_lightning import LightningDataModule\n",
        "from ...config import cfg\n",
        "from .sevir_dataloader import SEVIRDataLoader\n",
        "\n",
        "\n",
        "class SEVIRTorchDataset(TorchDataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 seq_len: int = 25,\n",
        "                 raw_seq_len: int = 49,\n",
        "                 sample_mode: str = \"sequent\",\n",
        "                 stride: int = 12,\n",
        "                 batch_size: int = 1,\n",
        "                 layout: str = \"NHWT\",\n",
        "                 num_shard: int = 1,\n",
        "                 rank: int = 0,\n",
        "                 split_mode: str = \"uneven\",\n",
        "                 sevir_catalog: Union[str, pd.DataFrame] = None,\n",
        "                 sevir_data_dir: str = None,\n",
        "                 start_date: datetime.datetime = None,\n",
        "                 end_date: datetime.datetime = None,\n",
        "                 datetime_filter = None,\n",
        "                 catalog_filter = \"default\",\n",
        "                 shuffle: bool = False,\n",
        "                 shuffle_seed: int = 1,\n",
        "                 output_type = np.float32,\n",
        "                 preprocess: bool = True,\n",
        "                 rescale_method: str = \"01\",\n",
        "                 verbose: bool = False):\n",
        "        super(SEVIRTorchDataset, self).__init__()\n",
        "        self.layout = layout\n",
        "        self.sevir_dataloader = SEVIRDataLoader(\n",
        "            data_types=[\"vil\", ],\n",
        "            seq_len=seq_len,\n",
        "            raw_seq_len=raw_seq_len,\n",
        "            sample_mode=sample_mode,\n",
        "            stride=stride,\n",
        "            batch_size=batch_size,\n",
        "            layout=layout,\n",
        "            num_shard=num_shard,\n",
        "            rank=rank,\n",
        "            split_mode=split_mode,\n",
        "            sevir_catalog=sevir_catalog,\n",
        "            sevir_data_dir=sevir_data_dir,\n",
        "            start_date=start_date,\n",
        "            end_date=end_date,\n",
        "            datetime_filter=datetime_filter,\n",
        "            catalog_filter=catalog_filter,\n",
        "            shuffle=shuffle,\n",
        "            shuffle_seed=shuffle_seed,\n",
        "            output_type=output_type,\n",
        "            preprocess=preprocess,\n",
        "            rescale_method=rescale_method,\n",
        "            downsample_dict=None,\n",
        "            verbose=verbose)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data_dict = self.sevir_dataloader._idx_sample(index=index)\n",
        "        return data_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.sevir_dataloader.__len__()\n",
        "\n",
        "    def collate_fn(self, data_dict_list):\n",
        "        r\"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        data_dict_list:  list[Dict[str, torch.Tensor]]\n",
        "        Returns\n",
        "        -------\n",
        "        merged_data: Dict[str, torch.Tensor]\n",
        "            batch_size = len(data_dict_list) * data_dict[\"key\"].batch_size\n",
        "        \"\"\"\n",
        "        batch_dim = self.layout.find('N')\n",
        "        data_list_dict = {\n",
        "            key: [data_dict[key]\n",
        "                  for data_dict in data_dict_list]\n",
        "            for key in data_dict_list[0]}\n",
        "        # TODO: key \"mask\" is not handled. Temporally fine since this func is not used\n",
        "        data_list_dict.pop(\"mask\", None)\n",
        "        merged_dict = {\n",
        "            key: torch.cat(data_list,\n",
        "                           dim=batch_dim)\n",
        "            for key, data_list in data_list_dict.items()}\n",
        "        merged_dict[\"mask\"] = None\n",
        "        return merged_dict\n",
        "\n",
        "    def get_torch_dataloader(self,\n",
        "                             outer_batch_size=1,\n",
        "                             collate_fn=None,\n",
        "                             num_workers=1):\n",
        "        # TODO: num_workers > 1\n",
        "        r\"\"\"\n",
        "        We set the batch_size in Dataset by default, so outer_batch_size should be 1.\n",
        "        In this case, not using `collate_fn` can save time.\n",
        "        \"\"\"\n",
        "        if outer_batch_size == 1:\n",
        "            collate_fn = lambda x:x[0]\n",
        "        else:\n",
        "            if collate_fn is None:\n",
        "                collate_fn = self.collate_fn\n",
        "        dataloader = DataLoader(\n",
        "            dataset=self,\n",
        "            batch_size=outer_batch_size,\n",
        "            collate_fn=collate_fn,\n",
        "            num_workers=num_workers)\n",
        "        return dataloader\n",
        "\n",
        "\n",
        "def check_aws():\n",
        "    r\"\"\"\n",
        "    Check if aws cli is installed.\n",
        "    \"\"\"\n",
        "    if os.system(\"which aws\") != 0:\n",
        "        raise RuntimeError(\"AWS CLI is not installed! Please install it first. See https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html\")\n",
        "\n",
        "\n",
        "def download_SEVIR(save_dir=None):\n",
        "    r\"\"\"\n",
        "    Downloaded dataset is saved in save_dir/sevir\n",
        "    \"\"\"\n",
        "\n",
        "    check_aws()\n",
        "\n",
        "    if save_dir is None:\n",
        "        save_dir = cfg.datasets_dir\n",
        "    sevir_dir = os.path.join(save_dir, \"sevir\")\n",
        "    if os.path.exists(sevir_dir):\n",
        "        raise FileExistsError(f\"Path to save SEVIR dataset {sevir_dir} already exists!\")\n",
        "    else:\n",
        "        os.makedirs(sevir_dir)\n",
        "        os.system(f\"aws s3 cp --no-sign-request s3://sevir/CATALOG.csv \"\n",
        "                  f\"{os.path.join(sevir_dir, 'CATALOG.csv')}\")\n",
        "        os.system(f\"aws s3 cp --no-sign-request --recursive s3://sevir/data/vil/2019/SEVIR_VIL_STORMEVENTS_2019_0701_1231.h5 \"\n",
        "                  f\"{os.path.join(sevir_dir, 'data', 'vil')}\")\n",
        "\n",
        "class SEVIRLightningDataModule(LightningDataModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 seq_len: int = 25,\n",
        "                 sample_mode: str = \"sequent\",\n",
        "                 stride: int = 12,\n",
        "                 batch_size: int = 1,\n",
        "                 layout: str = \"NHWT\",\n",
        "                 output_type = np.float32,\n",
        "                 preprocess: bool = True,\n",
        "                 rescale_method: str = \"01\",\n",
        "                 verbose: bool = False,\n",
        "                 # datamodule_only\n",
        "                 dataset_name: str = \"sevir\",\n",
        "                 start_date: Tuple[int] = None,\n",
        "                 train_val_split_date: Tuple[int] = (2019, 1, 1),\n",
        "                 train_test_split_date: Tuple[int] = (2019, 6, 1),\n",
        "                 end_date: Tuple[int] = None,\n",
        "                 num_workers: int = 1,\n",
        "                 ):\n",
        "        super(SEVIRLightningDataModule, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.sample_mode = sample_mode\n",
        "        self.stride = stride\n",
        "        self.batch_size = batch_size\n",
        "        self.layout = layout\n",
        "        self.output_type = output_type\n",
        "        self.preprocess = preprocess\n",
        "        self.rescale_method = rescale_method\n",
        "        self.verbose = verbose\n",
        "        self.num_workers = num_workers\n",
        "        if dataset_name == \"sevir\":\n",
        "            sevir_root_dir = os.path.join(cfg.datasets_dir, \"sevir\")\n",
        "            catalog_path = os.path.join(sevir_root_dir, \"CATALOG.csv\")\n",
        "            raw_data_dir = os.path.join(sevir_root_dir, \"data\")\n",
        "            raw_seq_len = 49\n",
        "            interval_real_time = 5\n",
        "            img_height = 384\n",
        "            img_width = 384\n",
        "        elif dataset_name == \"sevir_lr\":\n",
        "            sevir_root_dir = os.path.join(cfg.datasets_dir, \"sevir_lr\")\n",
        "            catalog_path = os.path.join(sevir_root_dir, \"CATALOG.csv\")\n",
        "            raw_data_dir = os.path.join(sevir_root_dir, \"data\")\n",
        "            raw_seq_len = 25\n",
        "            interval_real_time = 10\n",
        "            img_height = 128\n",
        "            img_width = 128\n",
        "        else:\n",
        "            raise ValueError(f\"Wrong dataset name {dataset_name}. Must be 'sevir' or 'sevir_lr'.\")\n",
        "        self.dataset_name = dataset_name\n",
        "        self.sevir_root_dir = sevir_root_dir\n",
        "        self.catalog_path = catalog_path\n",
        "        self.raw_data_dir = raw_data_dir\n",
        "        self.raw_seq_len = raw_seq_len\n",
        "        self.interval_real_time = interval_real_time\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "        # train val test split\n",
        "        self.start_date = datetime.datetime(*start_date) \\\n",
        "            if start_date is not None else None\n",
        "        self.train_val_split_date = datetime.datetime(*train_val_split_date)\n",
        "        self.train_test_split_date = datetime.datetime(*train_test_split_date)\n",
        "        self.end_date = datetime.datetime(*end_date) \\\n",
        "            if end_date is not None else None\n",
        "\n",
        "    def prepare_data(self) -> None:\n",
        "        if os.path.exists(self.sevir_root_dir):\n",
        "            # Further check\n",
        "            assert os.path.exists(self.catalog_path), f\"CATALOG.csv not found! Should be located at {self.catalog_path}\"\n",
        "            assert os.path.exists(self.raw_data_dir), f\"SEVIR data not found! Should be located at {self.raw_data_dir}\"\n",
        "        else:\n",
        "            if self.dataset_name == \"sevir\":\n",
        "                download_SEVIR()\n",
        "            else:  # \"sevir_lr\"\n",
        "                raise NotImplementedError\n",
        "\n",
        "    def setup(self, stage = None) -> None:\n",
        "        self.sevir_train = SEVIRTorchDataset(\n",
        "            sevir_catalog=self.catalog_path,\n",
        "            sevir_data_dir=self.raw_data_dir,\n",
        "            raw_seq_len=self.raw_seq_len,\n",
        "            split_mode=\"uneven\",\n",
        "            shuffle=True,\n",
        "            seq_len=self.seq_len,\n",
        "            stride=self.stride,\n",
        "            sample_mode=self.sample_mode,\n",
        "            batch_size=self.batch_size,\n",
        "            layout=self.layout,\n",
        "            num_shard=1, rank=0,\n",
        "            start_date=self.start_date,\n",
        "            end_date=self.train_val_split_date,\n",
        "            output_type=self.output_type,\n",
        "            preprocess=self.preprocess,\n",
        "            rescale_method=self.rescale_method,\n",
        "            verbose=self.verbose,)\n",
        "        self.sevir_val = SEVIRTorchDataset(\n",
        "            sevir_catalog=self.catalog_path,\n",
        "            sevir_data_dir=self.raw_data_dir,\n",
        "            raw_seq_len=self.raw_seq_len,\n",
        "            split_mode=\"uneven\",\n",
        "            shuffle=False,\n",
        "            seq_len=self.seq_len,\n",
        "            stride=self.stride,\n",
        "            sample_mode=self.sample_mode,\n",
        "            batch_size=self.batch_size,\n",
        "            layout=self.layout,\n",
        "            num_shard=1, rank=0,\n",
        "            start_date=self.train_val_split_date,\n",
        "            end_date=self.train_test_split_date,\n",
        "            output_type=self.output_type,\n",
        "            preprocess=self.preprocess,\n",
        "            rescale_method=self.rescale_method,\n",
        "            verbose=self.verbose, )\n",
        "        self.sevir_test = SEVIRTorchDataset(\n",
        "            sevir_catalog=self.catalog_path,\n",
        "            sevir_data_dir=self.raw_data_dir,\n",
        "            raw_seq_len=self.raw_seq_len,\n",
        "            split_mode=\"uneven\",\n",
        "            shuffle=False,\n",
        "            seq_len=self.seq_len,\n",
        "            stride=self.stride,\n",
        "            sample_mode=self.sample_mode,\n",
        "            batch_size=self.batch_size,\n",
        "            layout=self.layout,\n",
        "            num_shard=1, rank=0,\n",
        "            start_date=self.train_test_split_date,\n",
        "            end_date=self.end_date,\n",
        "            output_type=self.output_type,\n",
        "            preprocess=self.preprocess,\n",
        "            rescale_method=self.rescale_method,\n",
        "            verbose=self.verbose,)\n",
        "        self.sevir_predict = SEVIRTorchDataset(\n",
        "            sevir_catalog=self.catalog_path,\n",
        "            sevir_data_dir=self.raw_data_dir,\n",
        "            raw_seq_len=self.raw_seq_len,\n",
        "            split_mode=\"uneven\",\n",
        "            shuffle=False,\n",
        "            seq_len=self.seq_len,\n",
        "            stride=self.stride,\n",
        "            sample_mode=self.sample_mode,\n",
        "            batch_size=self.batch_size,\n",
        "            layout=self.layout,\n",
        "            num_shard=1, rank=0,\n",
        "            start_date=self.train_test_split_date,\n",
        "            end_date=self.end_date,\n",
        "            output_type=self.output_type,\n",
        "            preprocess=self.preprocess,\n",
        "            rescale_method=self.rescale_method,\n",
        "            verbose=self.verbose,)\n",
        "        \n",
        "    def train_dataloader(self):\n",
        "        return self.sevir_train.get_torch_dataloader(num_workers=self.num_workers)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.sevir_val.get_torch_dataloader(num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self.sevir_test.get_torch_dataloader(num_workers=self.num_workers)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return self.sevir_predict.get_torch_dataloader(num_workers=self.num_workers)\n",
        "\n",
        "    @property\n",
        "    def num_train_samples(self):\n",
        "        return len(self.sevir_train)\n",
        "\n",
        "    @property\n",
        "    def num_val_samples(self):\n",
        "        return len(self.sevir_val)\n",
        "\n",
        "    @property\n",
        "    def num_test_samples(self):\n",
        "        return len(self.sevir_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "xpwS03m2jBTo",
        "outputId": "5d961fa2-c666-46ed-d752-80f7dc926bf7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e79580243c78>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTorchDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightningDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msevir_dataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSEVIRDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "yr7wlzf-jE8l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wFxx4l_5jCBa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}